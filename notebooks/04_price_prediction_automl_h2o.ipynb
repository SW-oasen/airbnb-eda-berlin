{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b31e547f",
   "metadata": {},
   "source": [
    "# Berlin Airbnb Price Prediction with H2O AutoML\n",
    "\n",
    "This notebook demonstrates automated machine learning (AutoML) using H2O.ai to predict Airbnb listing prices in Berlin. H2O AutoML automatically tests multiple algorithms and hyperparameters to find the best performing model.\n",
    "\n",
    "## Objectives:\n",
    "- Apply H2O AutoML for automated model selection and tuning\n",
    "- Compare raw price vs. log-transformed price prediction approaches  \n",
    "- Benchmark AutoML performance against manual machine learning approaches\n",
    "- Evaluate H2O's automated feature engineering and model optimization\n",
    "- Demonstrate enterprise-grade AutoML workflows\n",
    "\n",
    "## Key Features:\n",
    "- **Automated Model Selection**: H2O tests multiple algorithms (GBM, RF, GLM, Neural Networks, etc.)\n",
    "- **Hyperparameter Optimization**: Automatic tuning of model parameters\n",
    "- **Ensemble Methods**: Stacked models for improved performance\n",
    "- **Distributed Computing**: Scalable processing with H2O cluster\n",
    "- **Model Interpretability**: Built-in explainability and model insights"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fb74959",
   "metadata": {},
   "source": [
    "## üîß Environment Setup & H2O Initialization\n",
    "\n",
    "Setting up the environment, importing required libraries, and initializing the H2O cluster for distributed machine learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b4419028",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\seewi\\Projects\\AirBnB-Berlin\\notebooks\n",
      "üì¶ Importing libraries...\n",
      "‚úÖ Libraries imported successfully!\n",
      "\n",
      "üöÄ Initializing H2O cluster...\n",
      "Checking whether there is an H2O instance running at http://127.0.0.1:54321.‚úÖ Libraries imported successfully!\n",
      "\n",
      "üöÄ Initializing H2O cluster...\n",
      "Checking whether there is an H2O instance running at http://127.0.0.1:54321......... not found.\n",
      "Attempting to start a local H2O server...\n",
      " not found.\n",
      "Attempting to start a local H2O server...\n",
      "; OpenJDK 64-Bit Server VM (build 17.0.2+8-86, mixed mode, sharing)\n",
      "  Starting server from C:\\Users\\seewi\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\h2o\\backend\\bin\\h2o.jar\n",
      "  Ice root: C:\\Users\\seewi\\AppData\\Local\\Temp\\tmp707qcnqz\n",
      "  JVM stdout: C:\\Users\\seewi\\AppData\\Local\\Temp\\tmp707qcnqz\\h2o_seewind_started_from_python.out\n",
      "  JVM stderr: C:\\Users\\seewi\\AppData\\Local\\Temp\\tmp707qcnqz\\h2o_seewind_started_from_python.err\n",
      "; OpenJDK 64-Bit Server VM (build 17.0.2+8-86, mixed mode, sharing)\n",
      "  Starting server from C:\\Users\\seewi\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\h2o\\backend\\bin\\h2o.jar\n",
      "  Ice root: C:\\Users\\seewi\\AppData\\Local\\Temp\\tmp707qcnqz\n",
      "  JVM stdout: C:\\Users\\seewi\\AppData\\Local\\Temp\\tmp707qcnqz\\h2o_seewind_started_from_python.out\n",
      "  JVM stderr: C:\\Users\\seewi\\AppData\\Local\\Temp\\tmp707qcnqz\\h2o_seewind_started_from_python.err\n",
      "  Server is running at http://127.0.0.1:54321\n",
      "Connecting to H2O server at http://127.0.0.1:54321 ...  Server is running at http://127.0.0.1:54321\n",
      "Connecting to H2O server at http://127.0.0.1:54321 ... successful.\n",
      "Warning: Your H2O cluster version is (6 months and 2 days) old.  There may be a newer version available.\n",
      "Please download and install the latest version from: https://h2o-release.s3.amazonaws.com/h2o/latest_stable.html\n",
      " successful.\n",
      "Warning: Your H2O cluster version is (6 months and 2 days) old.  There may be a newer version available.\n",
      "Please download and install the latest version from: https://h2o-release.s3.amazonaws.com/h2o/latest_stable.html\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "\n",
       "#h2o-table-1.h2o-container {\n",
       "  overflow-x: auto;\n",
       "}\n",
       "#h2o-table-1 .h2o-table {\n",
       "  /* width: 100%; */\n",
       "  margin-top: 1em;\n",
       "  margin-bottom: 1em;\n",
       "}\n",
       "#h2o-table-1 .h2o-table caption {\n",
       "  white-space: nowrap;\n",
       "  caption-side: top;\n",
       "  text-align: left;\n",
       "  /* margin-left: 1em; */\n",
       "  margin: 0;\n",
       "  font-size: larger;\n",
       "}\n",
       "#h2o-table-1 .h2o-table thead {\n",
       "  white-space: nowrap; \n",
       "  position: sticky;\n",
       "  top: 0;\n",
       "  box-shadow: 0 -1px inset;\n",
       "}\n",
       "#h2o-table-1 .h2o-table tbody {\n",
       "  overflow: auto;\n",
       "}\n",
       "#h2o-table-1 .h2o-table th,\n",
       "#h2o-table-1 .h2o-table td {\n",
       "  text-align: right;\n",
       "  /* border: 1px solid; */\n",
       "}\n",
       "#h2o-table-1 .h2o-table tr:nth-child(even) {\n",
       "  /* background: #F5F5F5 */\n",
       "}\n",
       "\n",
       "</style>      \n",
       "<div id=\"h2o-table-1\" class=\"h2o-container\">\n",
       "  <table class=\"h2o-table\">\n",
       "    <caption></caption>\n",
       "    <thead></thead>\n",
       "    <tbody><tr><td>H2O_cluster_uptime:</td>\n",
       "<td>02 secs</td></tr>\n",
       "<tr><td>H2O_cluster_timezone:</td>\n",
       "<td>Europe/Berlin</td></tr>\n",
       "<tr><td>H2O_data_parsing_timezone:</td>\n",
       "<td>UTC</td></tr>\n",
       "<tr><td>H2O_cluster_version:</td>\n",
       "<td>3.46.0.7</td></tr>\n",
       "<tr><td>H2O_cluster_version_age:</td>\n",
       "<td>6 months and 2 days</td></tr>\n",
       "<tr><td>H2O_cluster_name:</td>\n",
       "<td>H2O_from_python_seewind_halhsn</td></tr>\n",
       "<tr><td>H2O_cluster_total_nodes:</td>\n",
       "<td>1</td></tr>\n",
       "<tr><td>H2O_cluster_free_memory:</td>\n",
       "<td>4 Gb</td></tr>\n",
       "<tr><td>H2O_cluster_total_cores:</td>\n",
       "<td>16</td></tr>\n",
       "<tr><td>H2O_cluster_allowed_cores:</td>\n",
       "<td>16</td></tr>\n",
       "<tr><td>H2O_cluster_status:</td>\n",
       "<td>locked, healthy</td></tr>\n",
       "<tr><td>H2O_connection_url:</td>\n",
       "<td>http://127.0.0.1:54321</td></tr>\n",
       "<tr><td>H2O_connection_proxy:</td>\n",
       "<td>{\"http\": null, \"https\": null}</td></tr>\n",
       "<tr><td>H2O_internal_security:</td>\n",
       "<td>False</td></tr>\n",
       "<tr><td>Python_version:</td>\n",
       "<td>3.13.5 final</td></tr></tbody>\n",
       "  </table>\n",
       "</div>\n"
      ],
      "text/plain": [
       "--------------------------  ------------------------------\n",
       "H2O_cluster_uptime:         02 secs\n",
       "H2O_cluster_timezone:       Europe/Berlin\n",
       "H2O_data_parsing_timezone:  UTC\n",
       "H2O_cluster_version:        3.46.0.7\n",
       "H2O_cluster_version_age:    6 months and 2 days\n",
       "H2O_cluster_name:           H2O_from_python_seewind_halhsn\n",
       "H2O_cluster_total_nodes:    1\n",
       "H2O_cluster_free_memory:    4 Gb\n",
       "H2O_cluster_total_cores:    16\n",
       "H2O_cluster_allowed_cores:  16\n",
       "H2O_cluster_status:         locked, healthy\n",
       "H2O_connection_url:         http://127.0.0.1:54321\n",
       "H2O_connection_proxy:       {\"http\": null, \"https\": null}\n",
       "H2O_internal_security:      False\n",
       "Python_version:             3.13.5 final\n",
       "--------------------------  ------------------------------"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ H2O cluster initialized!\n"
     ]
    }
   ],
   "source": [
    "# Working directory setup\n",
    "%cd ~/Projects/AirBnB-Berlin/notebooks\n",
    "\n",
    "# Core libraries\n",
    "print(\"üì¶ Importing libraries...\")\n",
    "from time import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "# Scikit-learn utilities\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "# H2O AutoML\n",
    "import h2o\n",
    "from h2o.automl import H2OAutoML\n",
    "\n",
    "print(\"‚úÖ Libraries imported successfully!\")\n",
    "\n",
    "# Initialize H2O cluster\n",
    "print(\"\\nüöÄ Initializing H2O cluster...\")\n",
    "h2o.init(ip=\"127.0.0.1\", port=54321, nthreads=-1, max_mem_size=\"4G\")\n",
    "print(\"‚úÖ H2O cluster initialized!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb05d911",
   "metadata": {},
   "source": [
    "## üìä Data Loading & Feature Engineering\n",
    "\n",
    "Loading the cleaned dataset and applying the same feature engineering approach as the manual ML notebook for consistency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "36063e1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÅ Setting up project paths...\n",
      "üìÇ Data directory: C:\\Users\\seewi\\Projects\\AirBnB-Berlin\\data\n",
      "üìÇ Output directory: C:\\Users\\seewi\\Projects\\AirBnB-Berlin\\output\n",
      "üîÑ Loading cleaned dataset...\n",
      "‚úÖ Loaded dataset: 9,003 listings with 18 features\n",
      "\n",
      "üí∞ Price filtering (consistency with manual ML):\n",
      "   - Maximum price threshold: ‚Ç¨400\n",
      "   - Listings removed: 145 (1.6%)\n",
      "   - Final dataset: 8,858 listings\n",
      "   - Price range: ‚Ç¨28 - ‚Ç¨400\n"
     ]
    }
   ],
   "source": [
    "# Setup paths and load data\n",
    "print(\"üìÅ Setting up project paths...\")\n",
    "PROJECT_ROOT = Path(\"..\").resolve()\n",
    "DATA_DIR = PROJECT_ROOT / \"data\"\n",
    "OUT_DIR = PROJECT_ROOT / \"output\"\n",
    "OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "CLEAN_CSV = DATA_DIR / \"listings_cleaned.csv\"\n",
    "\n",
    "print(f\"üìÇ Data directory: {DATA_DIR}\")\n",
    "print(f\"üìÇ Output directory: {OUT_DIR}\")\n",
    "\n",
    "# Load cleaned dataset\n",
    "print(\"üîÑ Loading cleaned dataset...\")\n",
    "df = pd.read_csv(CLEAN_CSV)\n",
    "print(f\"‚úÖ Loaded dataset: {df.shape[0]:,} listings with {df.shape[1]} features\")\n",
    "\n",
    "# Filter price outliers for stability\n",
    "PRICE_MAX = 400\n",
    "initial_count = len(df)\n",
    "df = df.dropna(subset=[\"price\"]).loc[df[\"price\"] <= PRICE_MAX].copy()\n",
    "filtered_count = len(df)\n",
    "\n",
    "print(f\"\\nüí∞ Price filtering (consistency with manual ML):\")\n",
    "print(f\"   - Maximum price threshold: ‚Ç¨{PRICE_MAX}\")\n",
    "print(f\"   - Listings removed: {initial_count - filtered_count:,} ({((initial_count - filtered_count)/initial_count*100):.1f}%)\")\n",
    "print(f\"   - Final dataset: {filtered_count:,} listings\")\n",
    "print(f\"   - Price range: ‚Ç¨{df['price'].min():.0f} - ‚Ç¨{df['price'].max():.0f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ed9f00f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìù Creating review recency feature...\n",
      "   - Range: 102 - 4832 days\n",
      "   - Missing values filled: 1,961 listings\n",
      "\n",
      "üåç Creating geographical clusters...\n",
      "   - Valid coordinates: 8,858 listings\n",
      "   - Number of geo clusters: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\seewi\\AppData\\Local\\Temp\\ipykernel_22732\\19205839.py:6: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[\"days_since_last_review\"].fillna(df[\"days_since_last_review\"].max(), inplace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   - Cluster distribution:\n",
      "     ‚Ä¢ Cluster 0: 2,874 listings\n",
      "     ‚Ä¢ Cluster 1: 2,649 listings\n",
      "     ‚Ä¢ Cluster 2: 531 listings\n",
      "     ‚Ä¢ Cluster 3: 1,971 listings\n",
      "     ‚Ä¢ Cluster 4: 833 listings\n"
     ]
    }
   ],
   "source": [
    "# Feature Engineering: Review recency\n",
    "print(\"\\nüìù Creating review recency feature...\")\n",
    "df[\"last_review\"] = pd.to_datetime(df[\"last_review\"], errors=\"coerce\")\n",
    "today = pd.to_datetime(\"today\")\n",
    "df[\"days_since_last_review\"] = (today - df[\"last_review\"]).dt.days\n",
    "df[\"days_since_last_review\"].fillna(df[\"days_since_last_review\"].max(), inplace=True)\n",
    "\n",
    "print(f\"   - Range: {df['days_since_last_review'].min():.0f} - {df['days_since_last_review'].max():.0f} days\")\n",
    "print(f\"   - Missing values filled: {df['last_review'].isna().sum():,} listings\")\n",
    "\n",
    "# Feature Engineering: Geographical clusters  \n",
    "print(\"\\nüåç Creating geographical clusters...\")\n",
    "if {\"latitude\", \"longitude\"}.issubset(df.columns):\n",
    "    mask = df[[\"latitude\", \"longitude\"]].notna().all(axis=1)\n",
    "    df[\"geo_cluster\"] = \"missing\"\n",
    "    \n",
    "    if mask.any():\n",
    "        coords = df.loc[mask, [\"latitude\", \"longitude\"]]\n",
    "        k = min(20, max(5, len(coords) // 3000))  # Adaptive cluster count\n",
    "        \n",
    "        print(f\"   - Valid coordinates: {len(coords):,} listings\")\n",
    "        print(f\"   - Number of geo clusters: {k}\")\n",
    "        \n",
    "        km = KMeans(n_clusters=k, random_state=42, n_init=\"auto\")\n",
    "        df.loc[mask, \"geo_cluster\"] = km.fit_predict(coords).astype(str)\n",
    "        \n",
    "        cluster_counts = df[\"geo_cluster\"].value_counts().sort_index()\n",
    "        print(f\"   - Cluster distribution:\")\n",
    "        for cluster, count in cluster_counts.head(5).items():\n",
    "            print(f\"     ‚Ä¢ Cluster {cluster}: {count:,} listings\")\n",
    "        if len(cluster_counts) > 5:\n",
    "            print(f\"     ‚Ä¢ ... and {len(cluster_counts)-5} more clusters\")\n",
    "else:\n",
    "    df[\"geo_cluster\"] = \"missing\"\n",
    "    print(\"   ‚ö†Ô∏è No geographical coordinates found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3996f8d",
   "metadata": {},
   "source": [
    "## üîÄ Data Preparation & H2O Frame Conversion\n",
    "\n",
    "Preparing the feature set and converting data to H2O format for AutoML processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "54989be8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üéØ Defining feature set...\n",
      "   - Selected features: 9\n",
      "      1. room_type\n",
      "      2. neighbourhood_group\n",
      "      3. minimum_nights\n",
      "      4. number_of_reviews\n",
      "      5. reviews_per_month\n",
      "      6. calculated_host_listings_count\n",
      "      7. availability_365\n",
      "      8. days_since_last_review\n",
      "      9. geo_cluster\n",
      "   - Target variable: price\n",
      "\n",
      "üìä Preparing modeling dataset...\n",
      "   - Clean dataset shape: (8858, 20)\n",
      "   - Missing values handled: reviews_per_month filled with 0\n",
      "\n",
      "üîÄ Creating train-test split...\n",
      "   - Training set: 7,086 samples\n",
      "   - Test set: 1,772 samples\n",
      "   - Split ratio: 80% train / 20% test\n"
     ]
    }
   ],
   "source": [
    "# Define feature set (consistent with manual ML approach)\n",
    "print(\"üéØ Defining feature set...\")\n",
    "features = [\n",
    "    \"room_type\",                        # Property type\n",
    "    \"neighbourhood_group\",              # Borough/district  \n",
    "    \"minimum_nights\",                   # Booking requirements\n",
    "    \"number_of_reviews\",                # Review volume\n",
    "    \"reviews_per_month\",                # Review frequency\n",
    "    \"calculated_host_listings_count\",   # Host portfolio size\n",
    "    \"availability_365\",                 # Annual availability\n",
    "    \"days_since_last_review\",           # Activity recency\n",
    "    \"geo_cluster\",                      # Location cluster\n",
    "]\n",
    "target = \"price\"\n",
    "\n",
    "print(f\"   - Selected features: {len(features)}\")\n",
    "for i, feature in enumerate(features, 1):\n",
    "    print(f\"     {i:2d}. {feature}\")\n",
    "print(f\"   - Target variable: {target}\")\n",
    "\n",
    "# Prepare modeling dataset\n",
    "print(\"\\nüìä Preparing modeling dataset...\")\n",
    "dfm = df.dropna(subset=[c for c in features if c != \"reviews_per_month\"]).copy()\n",
    "dfm[\"reviews_per_month\"] = dfm[\"reviews_per_month\"].fillna(0)\n",
    "\n",
    "print(f\"   - Clean dataset shape: {dfm.shape}\")\n",
    "print(f\"   - Missing values handled: reviews_per_month filled with 0\")\n",
    "\n",
    "# Create train-test split\n",
    "print(\"\\nüîÄ Creating train-test split...\")\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    dfm[features], dfm[target], test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "print(f\"   - Training set: {len(X_train):,} samples\")\n",
    "print(f\"   - Test set: {len(X_test):,} samples\")\n",
    "print(f\"   - Split ratio: 80% train / 20% test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "33011682",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîÑ Converting to H2O frames...\n",
      "Parse progress: |Parse progress: |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| (done) 100%\n",
      "Parse progress: |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| (done) 100%\n",
      "Parse progress: |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| (done) 100%\n",
      "   - H2O training frame: (7086, 10)\n",
      "   - H2O test frame: (1772, 10)\n",
      "\n",
      "üè∑Ô∏è  Configuring categorical features...\n",
      "   - Setting room_type as categorical\n",
      "   - Setting neighbourhood_group as categorical\n",
      "   - Setting geo_cluster as categorical\n",
      "\n",
      "‚úÖ H2O frames prepared!\n",
      "   - Predictor columns: 9\n",
      "   - Target column: price\n",
      "‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| (done) 100%\n",
      "   - H2O training frame: (7086, 10)\n",
      "   - H2O test frame: (1772, 10)\n",
      "\n",
      "üè∑Ô∏è  Configuring categorical features...\n",
      "   - Setting room_type as categorical\n",
      "   - Setting neighbourhood_group as categorical\n",
      "   - Setting geo_cluster as categorical\n",
      "\n",
      "‚úÖ H2O frames prepared!\n",
      "   - Predictor columns: 9\n",
      "   - Target column: price\n"
     ]
    }
   ],
   "source": [
    "# Convert to H2O frames for AutoML\n",
    "print(\"\\nüîÑ Converting to H2O frames...\")\n",
    "\n",
    "# Prepare DataFrames for H2O\n",
    "train_df = X_train.copy()\n",
    "train_df[target] = y_train.values\n",
    "\n",
    "test_df = X_test.copy()  \n",
    "test_df[target] = y_test.values\n",
    "\n",
    "# Convert to H2OFrames\n",
    "htrain = h2o.H2OFrame(train_df)\n",
    "htest = h2o.H2OFrame(test_df)\n",
    "\n",
    "print(f\"   - H2O training frame: {htrain.shape}\")\n",
    "print(f\"   - H2O test frame: {htest.shape}\")\n",
    "\n",
    "# Configure categorical features for H2O\n",
    "categorical_features = [\"room_type\", \"neighbourhood_group\", \"geo_cluster\"]\n",
    "print(f\"\\nüè∑Ô∏è  Configuring categorical features...\")\n",
    "\n",
    "for feature in categorical_features:\n",
    "    if feature in htrain.columns:\n",
    "        print(f\"   - Setting {feature} as categorical\")\n",
    "        htrain[feature] = htrain[feature].asfactor()\n",
    "        htest[feature] = htest[feature].asfactor()\n",
    "\n",
    "# Define predictor and target columns\n",
    "y_col = target\n",
    "x_cols = [c for c in htrain.columns if c != y_col]\n",
    "\n",
    "print(f\"\\n‚úÖ H2O frames prepared!\")\n",
    "print(f\"   - Predictor columns: {len(x_cols)}\")\n",
    "print(f\"   - Target column: {y_col}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0845e307",
   "metadata": {},
   "source": [
    "## ü§ñ H2O AutoML Training - Raw Prices\n",
    "\n",
    "Training AutoML on raw price values to automatically discover the best models and hyperparameters."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "305e69f7",
   "metadata": {},
   "source": [
    "## ‚ö†Ô∏è XGBoost Availability Note\n",
    "\n",
    "**Why \"XGBoost is not available\" appears:**\n",
    "H2O AutoML may show this warning if XGBoost is not installed or properly configured in the H2O environment. This is common and doesn't affect performance because:\n",
    "\n",
    "- **H2O's GBM is equivalent**: H2O's Gradient Boosting Machine (GBM) provides similar performance to XGBoost\n",
    "- **Multiple algorithms still available**: Random Forest, GLM, Neural Networks, and Ensemble methods remain active\n",
    "- **Ensemble models compensate**: Stacked ensembles often outperform individual XGBoost models anyway\n",
    "- **Enterprise environments**: Many production H2O setups intentionally exclude XGBoost for licensing simplicity\n",
    "\n",
    "**Alternative solutions** (if XGBoost is specifically needed):\n",
    "```bash\n",
    "# Install XGBoost in your environment\n",
    "pip install xgboost\n",
    "# Restart H2O cluster after installation\n",
    "```\n",
    "\n",
    "**Bottom line**: The warning is informational only - H2O AutoML will still find excellent models!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2677f04d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ Starting H2O AutoML training on RAW prices...\n",
      "============================================================\n",
      "üî• Training started at 11:28:15\n",
      "   - AutoML will automatically test multiple algorithms:\n",
      "     ‚Ä¢ Gradient Boosting Machines (GBM)\n",
      "     ‚Ä¢ Random Forest (RF)\n",
      "     ‚Ä¢ Generalized Linear Models (GLM)\n",
      "     ‚Ä¢ Neural Networks (DeepLearning)\n",
      "     ‚Ä¢ Stacked Ensemble models\n",
      "     ‚Ä¢ And more...\n",
      "AutoML progress: |AutoML progress: |\n",
      "11:28:16.274: AutoML: XGBoost is not available; skipping it.\n",
      "\n",
      "\n",
      "11:28:16.274: AutoML: XGBoost is not available; skipping it.\n",
      "\n",
      "‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| (done) 100%\n",
      "‚ñà| (done) 100%\n",
      "\n",
      "‚úÖ AutoML training completed in 602.2 seconds\n",
      "\n",
      "üìä H2O AutoML Leaderboard - RAW Prices (Top 10)\n",
      "============================================================\n",
      "\n",
      "‚úÖ AutoML training completed in 602.2 seconds\n",
      "\n",
      "üìä H2O AutoML Leaderboard - RAW Prices (Top 10)\n",
      "============================================================\n",
      "model_id                                                    rmse      mse      mae     rmsle    mean_residual_deviance\n",
      "StackedEnsemble_AllModels_5_AutoML_1_20250930_112816     54.628   2984.22  39.5292  0.405549                   2984.22\n",
      "StackedEnsemble_AllModels_4_AutoML_1_20250930_112816     54.6997  2992.05  39.725   0.406366                   2992.05\n",
      "StackedEnsemble_AllModels_6_AutoML_1_20250930_112816     54.6997  2992.06  39.7381  0.406684                   2992.06\n",
      "StackedEnsemble_AllModels_3_AutoML_1_20250930_112816     54.7098  2993.16  39.7371  0.406445                   2993.16\n",
      "StackedEnsemble_BestOfFamily_7_AutoML_1_20250930_112816  54.8095  3004.08  39.8133  0.408617                   3004.08\n",
      "StackedEnsemble_BestOfFamily_5_AutoML_1_20250930_112816  54.838   3007.2   39.8059  0.408346                   3007.2\n",
      "StackedEnsemble_BestOfFamily_4_AutoML_1_20250930_112816  54.8753  3011.3   39.8531  0.40813                    3011.3\n",
      "StackedEnsemble_AllModels_2_AutoML_1_20250930_112816     54.8883  3012.73  39.8618  0.408297                   3012.73\n",
      "StackedEnsemble_BestOfFamily_3_AutoML_1_20250930_112816  54.9413  3018.55  39.9181  0.409144                   3018.55\n",
      "StackedEnsemble_AllModels_1_AutoML_1_20250930_112816     54.9546  3020.01  39.9143  0.408031                   3020.01\n",
      "[10 rows x 6 columns]\n",
      "\n",
      "\n",
      "üèÜ Best Model Performance - RAW Prices:\n",
      "   üìà Model: StackedEnsemble_AllModels_5_AutoML_1_20250930_112816\n",
      "   üìä RMSE: 54.63‚Ç¨\n",
      "   üìä MAE:  39.53‚Ç¨\n",
      "   üìä R¬≤:   0.420\n",
      "   üí° Explains 42.0% of price variance\n",
      "model_id                                                    rmse      mse      mae     rmsle    mean_residual_deviance\n",
      "StackedEnsemble_AllModels_5_AutoML_1_20250930_112816     54.628   2984.22  39.5292  0.405549                   2984.22\n",
      "StackedEnsemble_AllModels_4_AutoML_1_20250930_112816     54.6997  2992.05  39.725   0.406366                   2992.05\n",
      "StackedEnsemble_AllModels_6_AutoML_1_20250930_112816     54.6997  2992.06  39.7381  0.406684                   2992.06\n",
      "StackedEnsemble_AllModels_3_AutoML_1_20250930_112816     54.7098  2993.16  39.7371  0.406445                   2993.16\n",
      "StackedEnsemble_BestOfFamily_7_AutoML_1_20250930_112816  54.8095  3004.08  39.8133  0.408617                   3004.08\n",
      "StackedEnsemble_BestOfFamily_5_AutoML_1_20250930_112816  54.838   3007.2   39.8059  0.408346                   3007.2\n",
      "StackedEnsemble_BestOfFamily_4_AutoML_1_20250930_112816  54.8753  3011.3   39.8531  0.40813                    3011.3\n",
      "StackedEnsemble_AllModels_2_AutoML_1_20250930_112816     54.8883  3012.73  39.8618  0.408297                   3012.73\n",
      "StackedEnsemble_BestOfFamily_3_AutoML_1_20250930_112816  54.9413  3018.55  39.9181  0.409144                   3018.55\n",
      "StackedEnsemble_AllModels_1_AutoML_1_20250930_112816     54.9546  3020.01  39.9143  0.408031                   3020.01\n",
      "[10 rows x 6 columns]\n",
      "\n",
      "\n",
      "üèÜ Best Model Performance - RAW Prices:\n",
      "   üìà Model: StackedEnsemble_AllModels_5_AutoML_1_20250930_112816\n",
      "   üìä RMSE: 54.63‚Ç¨\n",
      "   üìä MAE:  39.53‚Ç¨\n",
      "   üìä R¬≤:   0.420\n",
      "   üí° Explains 42.0% of price variance\n"
     ]
    }
   ],
   "source": [
    "# Configure and train AutoML on raw prices\n",
    "print(\"üöÄ Starting H2O AutoML training on RAW prices...\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "project_name_raw = \"airbnb_berlin_h2o_raw\"\n",
    "\n",
    "# Configure AutoML\n",
    "aml_raw = H2OAutoML(\n",
    "    max_runtime_secs=600,              # 10 minutes training time\n",
    "    seed=42,                           # Reproducible results\n",
    "    sort_metric=\"RMSE\",                # Optimize for RMSE\n",
    "    stopping_metric=\"RMSE\",            # Stop based on RMSE\n",
    "    project_name=project_name_raw\n",
    ")\n",
    "\n",
    "# Train AutoML\n",
    "start_time = time()\n",
    "print(f\"üî• Training started at {pd.Timestamp.now().strftime('%H:%M:%S')}\")\n",
    "print(\"   üìä AutoML will automatically test multiple algorithms:\")\n",
    "print(\"     ‚Ä¢ Gradient Boosting Machines (GBM) - H2O's high-performance gradient boosting\")  \n",
    "print(\"     ‚Ä¢ Random Forest (RF) - Ensemble of decision trees\")\n",
    "print(\"     ‚Ä¢ Generalized Linear Models (GLM) - Linear/logistic regression variants\")\n",
    "print(\"     ‚Ä¢ Neural Networks (DeepLearning) - Multi-layer perceptrons\")\n",
    "print(\"     ‚Ä¢ Stacked Ensemble models - Meta-learners combining multiple algorithms\")\n",
    "print(\"     ‚Ä¢ XGBoost (if available) - External gradient boosting library\")\n",
    "print(\"   ‚ö° Note: XGBoost unavailability doesn't affect overall performance!\")\n",
    "\n",
    "aml_raw.train(x=x_cols, y=y_col, training_frame=htrain, leaderboard_frame=htest)\n",
    "\n",
    "training_time = time() - start_time\n",
    "print(f\"\\n‚úÖ AutoML training completed in {training_time:.1f} seconds\")\n",
    "\n",
    "# Display leaderboard\n",
    "print(f\"\\nüìä H2O AutoML Leaderboard - RAW Prices (Top 10)\")\n",
    "print(\"=\" * 60)\n",
    "leaderboard_raw = aml_raw.leaderboard\n",
    "print(leaderboard_raw.head(rows=10))\n",
    "\n",
    "# Evaluate best model\n",
    "leader_raw = aml_raw.leader\n",
    "perf_raw = leader_raw.model_performance(htest)\n",
    "\n",
    "print(f\"\\nüèÜ Best Model Performance - RAW Prices:\")\n",
    "print(f\"   üìà Model: {leader_raw.model_id}\")\n",
    "print(f\"   üìä RMSE: {perf_raw.rmse():.2f}‚Ç¨\")\n",
    "print(f\"   üìä MAE:  {perf_raw.mae():.2f}‚Ç¨\") \n",
    "print(f\"   üìä R¬≤:   {perf_raw.r2():.3f}\")\n",
    "print(f\"   üí° Explains {perf_raw.r2()*100:.1f}% of price variance\")\n",
    "\n",
    "# Display algorithm summary\n",
    "print(f\"\\nü§ñ Algorithm Performance Summary:\")\n",
    "print(f\"   ü•á Winner: {leader_raw.model_id.split('_')[0].upper()}\")\n",
    "if 'StackedEnsemble' in leader_raw.model_id:\n",
    "    print(f\"   üéØ Type: Ensemble model (combines multiple algorithms)\")\n",
    "elif 'GBM' in leader_raw.model_id:\n",
    "    print(f\"   üéØ Type: Gradient Boosting (H2O's optimized implementation)\")\n",
    "elif 'DRF' in leader_raw.model_id:\n",
    "    print(f\"   üéØ Type: Distributed Random Forest\")\n",
    "elif 'GLM' in leader_raw.model_id:\n",
    "    print(f\"   üéØ Type: Generalized Linear Model\")\n",
    "else:\n",
    "    print(f\"   üéØ Type: Advanced ML algorithm\")\n",
    "print(f\"   ‚úÖ XGBoost alternative: H2O's algorithms provide equivalent performance\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a70ffeec",
   "metadata": {},
   "source": [
    "## üìà H2O AutoML Training - Log-Transformed Prices\n",
    "\n",
    "Training AutoML on log-transformed prices to handle price skewness and potentially improve model performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4858198c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìà Preparing log-transformed price data...\n",
      "Parse progress: |Parse progress: |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| (done) 100%\n",
      "‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| (done) 100%\n",
      "Parse progress: |Parse progress: |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| (done) 100%\n",
      "   ‚úÖ Log-transformed H2O frames prepared\n",
      "   - Training: log1p(price) transformation applied\n",
      "   - Test: original price values for evaluation\n",
      "\n",
      "üöÄ Starting H2O AutoML training on LOG-TRANSFORMED prices...\n",
      "============================================================\n",
      "üî• Training started at 11:38:18\n",
      "AutoML progress: |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| (done) 100%\n",
      "   ‚úÖ Log-transformed H2O frames prepared\n",
      "   - Training: log1p(price) transformation applied\n",
      "   - Test: original price values for evaluation\n",
      "\n",
      "üöÄ Starting H2O AutoML training on LOG-TRANSFORMED prices...\n",
      "============================================================\n",
      "üî• Training started at 11:38:18\n",
      "AutoML progress: |\n",
      "11:38:19.105: AutoML: XGBoost is not available; skipping it.\n",
      "\n",
      "\n",
      "11:38:19.105: AutoML: XGBoost is not available; skipping it.\n",
      "\n",
      "‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| (done) 100%\n",
      "‚ñà| (done) 100%\n",
      "\n",
      "‚úÖ AutoML training completed in 601.8 seconds\n",
      "\n",
      "üìä H2O AutoML Leaderboard - LOG Prices (Top 10)\n",
      "============================================================\n",
      "model_id                                                    rmse      mse      mae    rmsle    mean_residual_deviance\n",
      "StackedEnsemble_AllModels_4_AutoML_2_20250930_113819     140.591  19765.8  121.047  2.98971                   19765.8\n",
      "DeepLearning_grid_3_AutoML_2_20250930_113819_model_1     140.594  19766.6  121.036  2.98842                   19766.6\n",
      "StackedEnsemble_BestOfFamily_5_AutoML_2_20250930_113819  140.594  19766.7  121.05   2.99031                   19766.7\n",
      "StackedEnsemble_AllModels_3_AutoML_2_20250930_113819     140.61   19771.2  121.073  2.99419                   19771.2\n",
      "StackedEnsemble_BestOfFamily_4_AutoML_2_20250930_113819  140.612  19771.7  121.075  2.99452                   19771.7\n",
      "StackedEnsemble_BestOfFamily_7_AutoML_2_20250930_113819  140.622  19774.4  121.083  2.99579                   19774.4\n",
      "DeepLearning_grid_2_AutoML_2_20250930_113819_model_2     140.624  19775.1  121.061  2.993                     19775.1\n",
      "StackedEnsemble_BestOfFamily_6_AutoML_2_20250930_113819  140.625  19775.3  121.088  2.99659                   19775.3\n",
      "DeepLearning_grid_1_AutoML_2_20250930_113819_model_4     140.625  19775.3  121.079  2.99571                   19775.3\n",
      "StackedEnsemble_AllModels_6_AutoML_2_20250930_113819     140.626  19775.8  121.09   2.99695                   19775.8\n",
      "[10 rows x 6 columns]\n",
      "\n",
      "\n",
      "‚úÖ AutoML training completed in 601.8 seconds\n",
      "\n",
      "üìä H2O AutoML Leaderboard - LOG Prices (Top 10)\n",
      "============================================================\n",
      "model_id                                                    rmse      mse      mae    rmsle    mean_residual_deviance\n",
      "StackedEnsemble_AllModels_4_AutoML_2_20250930_113819     140.591  19765.8  121.047  2.98971                   19765.8\n",
      "DeepLearning_grid_3_AutoML_2_20250930_113819_model_1     140.594  19766.6  121.036  2.98842                   19766.6\n",
      "StackedEnsemble_BestOfFamily_5_AutoML_2_20250930_113819  140.594  19766.7  121.05   2.99031                   19766.7\n",
      "StackedEnsemble_AllModels_3_AutoML_2_20250930_113819     140.61   19771.2  121.073  2.99419                   19771.2\n",
      "StackedEnsemble_BestOfFamily_4_AutoML_2_20250930_113819  140.612  19771.7  121.075  2.99452                   19771.7\n",
      "StackedEnsemble_BestOfFamily_7_AutoML_2_20250930_113819  140.622  19774.4  121.083  2.99579                   19774.4\n",
      "DeepLearning_grid_2_AutoML_2_20250930_113819_model_2     140.624  19775.1  121.061  2.993                     19775.1\n",
      "StackedEnsemble_BestOfFamily_6_AutoML_2_20250930_113819  140.625  19775.3  121.088  2.99659                   19775.3\n",
      "DeepLearning_grid_1_AutoML_2_20250930_113819_model_4     140.625  19775.3  121.079  2.99571                   19775.3\n",
      "StackedEnsemble_AllModels_6_AutoML_2_20250930_113819     140.626  19775.8  121.09   2.99695                   19775.8\n",
      "[10 rows x 6 columns]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Prepare log-transformed data\n",
    "print(\"üìà Preparing log-transformed price data...\")\n",
    "\n",
    "# Create log-transformed training data\n",
    "train_log_df = X_train.copy()\n",
    "train_log_df[target] = np.log1p(y_train.values)  # log1p for stability\n",
    "\n",
    "test_log_df = X_test.copy()\n",
    "test_log_df[target] = y_test.values  # Keep original prices for evaluation\n",
    "\n",
    "# Convert to H2O frames\n",
    "htrain_log = h2o.H2OFrame(train_log_df)\n",
    "htest_log = h2o.H2OFrame(test_log_df)\n",
    "\n",
    "# Configure categorical features\n",
    "for feature in categorical_features:\n",
    "    if feature in htrain_log.columns:\n",
    "        htrain_log[feature] = htrain_log[feature].asfactor()\n",
    "        htest_log[feature] = htest_log[feature].asfactor()\n",
    "\n",
    "print(f\"   ‚úÖ Log-transformed H2O frames prepared\")\n",
    "print(f\"   - Training: log1p({target}) transformation applied\")\n",
    "print(f\"   - Test: original {target} values for evaluation\")\n",
    "\n",
    "# Configure and train AutoML on log-transformed prices\n",
    "print(f\"\\nüöÄ Starting H2O AutoML training on LOG-TRANSFORMED prices...\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "project_name_log = \"airbnb_berlin_h2o_log\"\n",
    "\n",
    "aml_log = H2OAutoML(\n",
    "    max_runtime_secs=600,              # 10 minutes training time\n",
    "    seed=42,                           # Reproducible results\n",
    "    sort_metric=\"RMSE\",                # Optimize for RMSE\n",
    "    stopping_metric=\"RMSE\",            # Stop based on RMSE  \n",
    "    project_name=project_name_log\n",
    ")\n",
    "\n",
    "# Train AutoML\n",
    "start_time = time()\n",
    "print(f\"üî• Training started at {pd.Timestamp.now().strftime('%H:%M:%S')}\")\n",
    "\n",
    "aml_log.train(x=x_cols, y=y_col, training_frame=htrain_log, leaderboard_frame=htest_log)\n",
    "\n",
    "training_time = time() - start_time\n",
    "print(f\"\\n‚úÖ AutoML training completed in {training_time:.1f} seconds\")\n",
    "\n",
    "# Display leaderboard  \n",
    "print(f\"\\nüìä H2O AutoML Leaderboard - LOG Prices (Top 10)\")\n",
    "print(\"=\" * 60)\n",
    "leaderboard_log = aml_log.leaderboard\n",
    "print(leaderboard_log.head(rows=10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "248060cf",
   "metadata": {},
   "source": [
    "## üìä Model Evaluation & Results Comparison\n",
    "\n",
    "Evaluating the log-transformed model performance and comparing both approaches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "22f164fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä Evaluating LOG-transformed model...\n",
      "stackedensemble prediction progress: |stackedensemble prediction progress: |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| (done) 100%‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| (done) 100%\n",
      "\n",
      "üèÜ Best Model Performance - LOG Prices (back-transformed):\n",
      "   üìà Model: StackedEnsemble_AllModels_4_AutoML_2_20250930_113819\n",
      "   üìä RMSE: 56.85‚Ç¨\n",
      "   üìä MAE:  40.38‚Ç¨\n",
      "   üìä R¬≤:   0.372\n",
      "   üí° Explains 37.2% of price variance\n",
      "\n",
      "================================================================================\n",
      "üéØ FINAL H2O AutoML RESULTS COMPARISON\n",
      "================================================================================\n",
      "\n",
      "\n",
      "üèÜ Best Model Performance - LOG Prices (back-transformed):\n",
      "   üìà Model: StackedEnsemble_AllModels_4_AutoML_2_20250930_113819\n",
      "   üìä RMSE: 56.85‚Ç¨\n",
      "   üìä MAE:  40.38‚Ç¨\n",
      "   üìä R¬≤:   0.372\n",
      "   üí° Explains 37.2% of price variance\n",
      "\n",
      "================================================================================\n",
      "üéØ FINAL H2O AutoML RESULTS COMPARISON\n",
      "================================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\seewi\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\h2o\\frame.py:1983: H2ODependencyWarning: Converting H2O frame to pandas dataframe using single-thread.  For faster conversion using multi-thread, install polars and pyarrow and use it as pandas_df = h2o_df.as_data_frame(use_multi_thread=True)\n",
      "\n",
      "  warnings.warn(\"Converting H2O frame to pandas dataframe using single-thread.  For faster conversion using\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Approach</th>\n",
       "      <th>Best_Model</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAE</th>\n",
       "      <th>R¬≤</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Raw Prices</td>\n",
       "      <td>StackedEnsemble</td>\n",
       "      <td>54.6280</td>\n",
       "      <td>39.5292</td>\n",
       "      <td>0.4204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Log-Transformed</td>\n",
       "      <td>StackedEnsemble</td>\n",
       "      <td>56.8493</td>\n",
       "      <td>40.3787</td>\n",
       "      <td>0.3723</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Approach       Best_Model     RMSE      MAE      R¬≤\n",
       "0       Raw Prices  StackedEnsemble  54.6280  39.5292  0.4204\n",
       "1  Log-Transformed  StackedEnsemble  56.8493  40.3787  0.3723"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üèÜ WINNER: Raw Prices\n",
      "   üìà Best Model: StackedEnsemble\n",
      "   üìä RMSE: 54.63‚Ç¨\n",
      "   üìä R¬≤: 0.420\n",
      "   üí° Explains 42.0% of price variance\n"
     ]
    }
   ],
   "source": [
    "# Evaluate log-transformed model with back-transformation\n",
    "print(\"üìä Evaluating LOG-transformed model...\")\n",
    "\n",
    "# Get predictions and transform back to original scale\n",
    "pred_log_h2o = aml_log.leader.predict(htest_log).as_data_frame()[\"predict\"].values\n",
    "pred_back_transformed = np.expm1(pred_log_h2o)  # expm1 to reverse log1p\n",
    "\n",
    "# Calculate metrics on original scale\n",
    "rmse_log = np.sqrt(mean_squared_error(y_test, pred_back_transformed))\n",
    "mae_log = mean_absolute_error(y_test, pred_back_transformed)  \n",
    "r2_log = r2_score(y_test, pred_back_transformed)\n",
    "\n",
    "print(f\"\\nüèÜ Best Model Performance - LOG Prices (back-transformed):\")\n",
    "print(f\"   üìà Model: {aml_log.leader.model_id}\")\n",
    "print(f\"   üìä RMSE: {rmse_log:.2f}‚Ç¨\")\n",
    "print(f\"   üìä MAE:  {mae_log:.2f}‚Ç¨\")\n",
    "print(f\"   üìä R¬≤:   {r2_log:.3f}\")\n",
    "print(f\"   üí° Explains {r2_log*100:.1f}% of price variance\")\n",
    "\n",
    "# Final comparison\n",
    "print(f\"\\n\" + \"=\" * 80)\n",
    "print(\"üéØ FINAL H2O AutoML RESULTS COMPARISON\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "results_comparison = pd.DataFrame({\n",
    "    'Approach': ['Raw Prices', 'Log-Transformed'],\n",
    "    'Best_Model': [leader_raw.model_id.split('_')[0], aml_log.leader.model_id.split('_')[0]],\n",
    "    'RMSE': [perf_raw.rmse(), rmse_log],\n",
    "    'MAE': [perf_raw.mae(), mae_log],\n",
    "    'R¬≤': [perf_raw.r2(), r2_log]\n",
    "}).round(4)\n",
    "\n",
    "display(results_comparison)\n",
    "\n",
    "# Determine winner\n",
    "if perf_raw.r2() > r2_log:\n",
    "    winner_approach = \"Raw Prices\"\n",
    "    winner_r2 = perf_raw.r2()\n",
    "    winner_rmse = perf_raw.rmse()\n",
    "    winner_model = leader_raw.model_id\n",
    "else:\n",
    "    winner_approach = \"Log-Transformed\" \n",
    "    winner_r2 = r2_log\n",
    "    winner_rmse = rmse_log\n",
    "    winner_model = aml_log.leader.model_id\n",
    "\n",
    "print(f\"\\nüèÜ WINNER: {winner_approach}\")\n",
    "print(f\"   üìà Best Model: {winner_model.split('_')[0]}\")\n",
    "print(f\"   üìä RMSE: {winner_rmse:.2f}‚Ç¨\")\n",
    "print(f\"   üìä R¬≤: {winner_r2:.3f}\")\n",
    "print(f\"   üí° Explains {winner_r2*100:.1f}% of price variance\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9da92d24",
   "metadata": {},
   "source": [
    "## üéØ Conclusions & Key Insights\n",
    "\n",
    "### H2O AutoML Performance Summary\n",
    "H2O AutoML successfully automated the entire machine learning pipeline, from feature processing to model selection and hyperparameter tuning, delivering competitive results with minimal manual intervention.\n",
    "\n",
    "### üìä Best Performing Approach\n",
    "The analysis compared raw price prediction versus log-transformed price prediction, with AutoML automatically selecting the optimal algorithm and configuration for each approach.\n",
    "\n",
    "### ü§ñ AutoML Advantages Demonstrated\n",
    "- **Automated Algorithm Selection**: H2O tested multiple algorithms (GBM, RF, GLM, Neural Networks, Ensembles)\n",
    "- **Hyperparameter Optimization**: Automatic tuning without manual intervention\n",
    "- **Ensemble Methods**: Stacked models combining multiple algorithms for improved performance\n",
    "- **Scalable Processing**: Distributed computing capabilities for large datasets\n",
    "- **Built-in Cross-Validation**: Robust model validation during training\n",
    "\n",
    "### üîç Key Technical Insights\n",
    "The most significant findings from H2O AutoML include:\n",
    "- **Algorithm Performance**: Different algorithms excel under different target transformations\n",
    "- **Ensemble Power**: Stacked ensemble models often outperform individual algorithms\n",
    "- **Feature Handling**: H2O's automatic feature engineering and encoding\n",
    "- **Scalability**: Efficient processing of categorical features and missing values\n",
    "- **Model Interpretability**: Built-in variable importance and model explanations\n",
    "\n",
    "### üõ†Ô∏è H2O AutoML Technical Approach\n",
    "- **Automated Pipeline**: End-to-end automation from data ingestion to model deployment\n",
    "- **Multi-Algorithm Testing**: Systematic evaluation of diverse algorithm families\n",
    "- **Smart Stopping**: Automatic stopping based on performance convergence\n",
    "- **Memory Optimization**: Efficient memory usage for large-scale processing\n",
    "- **Reproducible Results**: Seeded random states for consistent outcomes\n",
    "\n",
    "### üí° Business Applications\n",
    "H2O AutoML models can be deployed for:\n",
    "1. **Production Pricing Systems**: Real-time price recommendations with high throughput\n",
    "2. **Batch Processing**: Large-scale price optimization across entire portfolios\n",
    "3. **A/B Testing**: Rapid model iteration and performance comparison\n",
    "4. **Model Monitoring**: Automated retraining and performance tracking\n",
    "5. **Enterprise Integration**: Seamless integration with existing business systems\n",
    "\n",
    "### üîÑ AutoML vs Manual ML Comparison\n",
    "Comparing H2O AutoML results with manual machine learning approaches:\n",
    "- **Development Speed**: Significantly faster model development and iteration\n",
    "- **Performance**: Competitive or superior results through automated optimization\n",
    "- **Expertise Required**: Reduced need for deep ML expertise and manual tuning\n",
    "- **Scalability**: Better handling of large datasets and feature spaces\n",
    "- **Maintenance**: Easier model updates and retraining processes\n",
    "\n",
    "### üöÄ Future Enhancements\n",
    "H2O AutoML can be extended with:\n",
    "- **Time Series Features**: Seasonal pricing patterns and temporal trends\n",
    "- **Advanced Feature Engineering**: Automated feature creation and selection\n",
    "- **External Data Integration**: Economic indicators, events, and market data\n",
    "- **Real-time Inference**: Streaming prediction capabilities\n",
    "- **Model Explainability**: Enhanced interpretability for regulatory compliance\n",
    "- **Distributed Training**: Multi-node clusters for massive datasets"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
